# Problem setting

With n = 100, p is {1, 0.1, 0.001}

# Analysis of the results


From mmas.pdf
F1:
- after 100 function evaluations, MMAS and MMAS* with p = 0.01 performs slightly worse than the other configurations
- they also take the longest to reach the optimal function value
- the majority of configurations reach the optimum after around 1000 function evaluations

F2:
- all configurations perform very similar to each other and reach the optimum at around 10000 function evaluations


F18:
- both MMAS and MMAS* with the smallest p value of 0.01 perform significantly worse in the realm of 100 to 1000 function evaluations
- but outside of that they perform similar to the other configurations
- the remaining configurations perform almost identical to each other


# Comparison to results from Exercise 2

F1:
- in Exercise 2, none of the algorithms reached a function value of 100, whereas in Exercise 4, all configurations reached the optimum of 100
- the curves in Exercise 3 are also much steeper, suggesting quicker improvements in function value per function evaluations

F2:
- Similarly to F1, none of the algorithms in Exercise 2 reached the optimum of 100, while in Exercise 4, all configurations reached it
- also the curves are again much steeper

F18:
- again the MMAS and MMAS* algorithms need fewer function evaluations to increase the function value compared to Exercise 2
- looking at the shape of the curves of Exercise 4, the main improvement happens between 100 and 1000 function evaluations, where the curves are significantly steeper than those in Exercise 2



